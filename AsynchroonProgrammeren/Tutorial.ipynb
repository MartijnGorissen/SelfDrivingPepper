{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting asyncio\n",
      "  Downloading asyncio-3.4.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "Downloading asyncio-3.4.3-py3-none-any.whl (101 kB)\n",
      "   ---------------------------------------- 0.0/101.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/101.8 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 10.2/101.8 kB ? eta -:--:--\n",
      "   ----------- --------------------------- 30.7/101.8 kB 435.7 kB/s eta 0:00:01\n",
      "   ----------------------------------- --- 92.2/101.8 kB 871.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- 101.8/101.8 kB 839.7 kB/s eta 0:00:00\n",
      "Installing collected packages: asyncio\n",
      "Successfully installed asyncio-3.4.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install -U asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial asynchroon!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    print('Tim')\n",
    "    await foo('Textual')\n",
    "    print('Done')\n",
    "\n",
    "async def foo(text):\n",
    "    print(text)\n",
    "    await asyncio.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tim\n",
      "Textual\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.9.4-cp312-cp312-win_amd64.whl.metadata (7.7 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\crazy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp)\n",
      "  Downloading frozenlist-1.4.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp)\n",
      "  Downloading multidict-6.0.5-cp312-cp312-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp)\n",
      "  Downloading yarl-1.9.4-cp312-cp312-win_amd64.whl.metadata (32 kB)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\crazy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp) (3.4)\n",
      "Downloading aiohttp-3.9.4-cp312-cp312-win_amd64.whl (368 kB)\n",
      "   ---------------------------------------- 0.0/368.8 kB ? eta -:--:--\n",
      "   ---------------------------- ----------- 266.2/368.8 kB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 368.8/368.8 kB 4.5 MB/s eta 0:00:00\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.4.1-cp312-cp312-win_amd64.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.5/50.5 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading multidict-6.0.5-cp312-cp312-win_amd64.whl (27 kB)\n",
      "Downloading yarl-1.9.4-cp312-cp312-win_amd64.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 76.4/76.4 kB 4.1 MB/s eta 0:00:00\n",
      "Installing collected packages: multidict, frozenlist, yarl, aiosignal, aiohttp\n",
      "Successfully installed aiohttp-3.9.4 aiosignal-1.3.1 frozenlist-1.4.1 multidict-6.0.5 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from https://jsonplaceholder.typicode.com/posts/1:\n",
      "{\n",
      "  \"userId\": 1,\n",
      "  \"id\": 1,\n",
      "  \"title\": \"sunt aut facere repellat provident occaecati excepturi optio reprehenderit\",\n",
      "  \"body\": \"quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\"\n",
      "}\n",
      "\n",
      "Data from https://jsonplaceholder.typicode.com/posts/2:\n",
      "{\n",
      "  \"userId\": 1,\n",
      "  \"id\": 2,\n",
      "  \"title\": \"qui est esse\",\n",
      "  \"body\": \"est rerum tempore vitae\\nsequi sint nihil reprehenderit dolor beatae ea dolores neque\\nfugiat blanditiis voluptate porro vel nihil molestiae ut reiciendis\\nqui aperiam non debitis possimus qui neque nisi nulla\"\n",
      "}\n",
      "\n",
      "Data from https://jsonplaceholder.typicode.com/posts/3:\n",
      "{\n",
      "  \"userId\": 1,\n",
      "  \"id\": 3,\n",
      "  \"title\": \"ea molestias quasi exercitationem repellat qui ipsa sit aut\",\n",
      "  \"body\": \"et iusto sed quo iure\\nvoluptatem occaecati omnis eligendi aut ad\\nvoluptatem doloribus vel accusantium quis pariatur\\nmolestiae porro eius odio et labore et velit aut\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "\n",
    "async def fetch_data(url):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(url) as response:\n",
    "            return await response.text()\n",
    "\n",
    "async def main():\n",
    "    # List of URLs to fetch data from\n",
    "    urls = [\n",
    "        'https://jsonplaceholder.typicode.com/posts/1',\n",
    "        'https://jsonplaceholder.typicode.com/posts/2',\n",
    "        'https://jsonplaceholder.typicode.com/posts/3'\n",
    "    ]\n",
    "\n",
    "    # Fetch data from each URL concurrently\n",
    "    tasks = [fetch_data(url) for url in urls]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "\n",
    "    # Print results\n",
    "    for url, result in zip(urls, results):\n",
    "        print(f\"Data from {url}:\")\n",
    "        print(result)\n",
    "        print()\n",
    "\n",
    "# Run the main coroutine\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from https://jsonplaceholder.typicode.com/posts/1:\n",
      "{\n",
      "  \"userId\": 1,\n",
      "  \"id\": 1,\n",
      "  \"title\": \"sunt aut facere repellat provident occaecati excepturi optio reprehenderit\",\n",
      "  \"body\": \"quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\"\n",
      "}\n",
      "\n",
      "Data from https://jsonplaceholder.typicode.com/posts/2:\n",
      "{\n",
      "  \"userId\": 1,\n",
      "  \"id\": 2,\n",
      "  \"title\": \"qui est esse\",\n",
      "  \"body\": \"est rerum tempore vitae\\nsequi sint nihil reprehenderit dolor beatae ea dolores neque\\nfugiat blanditiis voluptate porro vel nihil molestiae ut reiciendis\\nqui aperiam non debitis possimus qui neque nisi nulla\"\n",
      "}\n",
      "\n",
      "Data from https://jsonplaceholder.typicode.com/posts/3:\n",
      "{\n",
      "  \"userId\": 1,\n",
      "  \"id\": 3,\n",
      "  \"title\": \"ea molestias quasi exercitationem repellat qui ipsa sit aut\",\n",
      "  \"body\": \"et iusto sed quo iure\\nvoluptatem occaecati omnis eligendi aut ad\\nvoluptatem doloribus vel accusantium quis pariatur\\nmolestiae porro eius odio et labore et velit aut\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def fetch_data(url):\n",
    "    response = requests.get(url)\n",
    "    return response.text\n",
    "\n",
    "def main():\n",
    "    # List of URLs to fetch data from\n",
    "    urls = [\n",
    "        'https://jsonplaceholder.typicode.com/posts/1',\n",
    "        'https://jsonplaceholder.typicode.com/posts/2',\n",
    "        'https://jsonplaceholder.typicode.com/posts/3'\n",
    "    ]\n",
    "\n",
    "    # Fetch data from each URL sequentially\n",
    "    results = [fetch_data(url) for url in urls]\n",
    "\n",
    "    # Print results\n",
    "    for url, result in zip(urls, results):\n",
    "        print(f\"Data from {url}:\")\n",
    "        print(result)\n",
    "        print()\n",
    "\n",
    "# Run the main function\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 training completed.\n",
      "Model 2 training completed.\n",
      "Model 3 training completed.\n",
      "Model 4 training completed.\n",
      "Model 5 training completed.\n",
      "Model 1 evaluation completed.\n",
      "Model 2 evaluation completed.\n",
      "Model 3 evaluation completed.\n",
      "Model 4 evaluation completed.\n",
      "Model 5 evaluation completed.\n",
      "Model 1 Accuracy: 0.868\n",
      "Model 2 Accuracy: 0.862\n",
      "Model 3 Accuracy: 0.86\n",
      "Model 4 Accuracy: 0.856\n",
      "Model 5 Accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "async def train_model(X, y, model_number):\n",
    "    model = RandomForestClassifier(n_estimators=100)\n",
    "    model.fit(X, y)\n",
    "    print(f\"Model {model_number} training completed.\")\n",
    "    return model\n",
    "\n",
    "async def evaluate_model(model, X_test, y_test, model_number):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model {model_number} evaluation completed.\")\n",
    "    return accuracy\n",
    "\n",
    "async def main():\n",
    "    # Generate synthetic data\n",
    "    X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "    \n",
    "    # Split data into train and test sets\n",
    "    split_index = len(X) // 2\n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "    # Train multiple models concurrently\n",
    "    tasks = [train_model(X_train, y_train, i+1) for i in range(5)]\n",
    "    trained_models = await asyncio.gather(*tasks)\n",
    "\n",
    "    # Evaluate each trained model\n",
    "    evaluation_tasks = [evaluate_model(model, X_test, y_test, i+1) for i, model in enumerate(trained_models)]\n",
    "    accuracies = await asyncio.gather(*evaluation_tasks)\n",
    "\n",
    "    # Print accuracies\n",
    "    for i, accuracy in enumerate(accuracies):\n",
    "        print(f\"Model {i+1} Accuracy: {accuracy}\")\n",
    "\n",
    "# Run the main coroutine\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 training completed.\n",
      "Model 2 training completed.\n",
      "Model 3 training completed.\n",
      "Model 4 training completed.\n",
      "Model 5 training completed.\n",
      "Model 1 evaluation completed.\n",
      "Model 2 evaluation completed.\n",
      "Model 3 evaluation completed.\n",
      "Model 4 evaluation completed.\n",
      "Model 5 evaluation completed.\n",
      "Model 1 Accuracy: 0.854\n",
      "Model 2 Accuracy: 0.858\n",
      "Model 3 Accuracy: 0.858\n",
      "Model 4 Accuracy: 0.854\n",
      "Model 5 Accuracy: 0.854\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_model(X, y, model_number):\n",
    "    model = RandomForestClassifier(n_estimators=100)\n",
    "    model.fit(X, y)\n",
    "    print(f\"Model {model_number} training completed.\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, model_number):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model {model_number} evaluation completed.\")\n",
    "    return accuracy\n",
    "\n",
    "def main():\n",
    "    # Generate synthetic data\n",
    "    X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "    \n",
    "    # Split data into train and test sets\n",
    "    split_index = len(X) // 2\n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "    # Train multiple models sequentially\n",
    "    trained_models = []\n",
    "    for i in range(5):\n",
    "        model = train_model(X_train, y_train, i+1)\n",
    "        trained_models.append(model)\n",
    "\n",
    "    # Evaluate each trained model sequentially\n",
    "    accuracies = []\n",
    "    for i, model in enumerate(trained_models):\n",
    "        accuracy = evaluate_model(model, X_test, y_test, i+1)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    # Print accuracies\n",
    "    for i, accuracy in enumerate(accuracies):\n",
    "        print(f\"Model {i+1} Accuracy: {accuracy}\")\n",
    "\n",
    "# Run the main function\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asynchio test voor Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running two synchronous DL models:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crazy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8585 - loss: 0.4795 - val_accuracy: 0.9570 - val_loss: 0.1452\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9552 - loss: 0.1516 - val_accuracy: 0.9688 - val_loss: 0.1055\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9657 - loss: 0.1119 - val_accuracy: 0.9722 - val_loss: 0.0904\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9723 - loss: 0.0915 - val_accuracy: 0.9768 - val_loss: 0.0764\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9760 - loss: 0.0755 - val_accuracy: 0.9757 - val_loss: 0.0732\n",
      "313/313 - 0s - 970us/step - accuracy: 0.9757 - loss: 0.0732\n",
      "\n",
      "Test accuracy (sync): 0.9757000207901001\n",
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8634 - loss: 0.4776 - val_accuracy: 0.9601 - val_loss: 0.1403\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9565 - loss: 0.1496 - val_accuracy: 0.9707 - val_loss: 0.0988\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9676 - loss: 0.1075 - val_accuracy: 0.9740 - val_loss: 0.0839\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9729 - loss: 0.0879 - val_accuracy: 0.9779 - val_loss: 0.0721\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9771 - loss: 0.0735 - val_accuracy: 0.9784 - val_loss: 0.0723\n",
      "313/313 - 0s - 1ms/step - accuracy: 0.9784 - loss: 0.0723\n",
      "\n",
      "Test accuracy (sync): 0.9783999919891357\n"
     ]
    }
   ],
   "source": [
    "# Define a function to create and train a small neural network model (synchronous version)\n",
    "def train_neural_network_sync():\n",
    "    # Load the MNIST dataset\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "    \n",
    "    # Normalize the data\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    \n",
    "    # Create a simple neural network model\n",
    "    model = keras.Sequential([\n",
    "        layers.Flatten(input_shape=(28, 28)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "    \n",
    "    # Evaluate the model\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "    \n",
    "    print(\"\\nTest accuracy (sync):\", test_acc)\n",
    "\n",
    "# Run two DL models synchronously in the same code cell\n",
    "print(\"Running two synchronous DL models:\")\n",
    "train_neural_network_sync()\n",
    "train_neural_network_sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running two asynchronous DL models:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crazy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8642 - loss: 0.4726 - val_accuracy: 0.9588 - val_loss: 0.1372\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8567 - loss: 0.4928 - val_accuracy: 0.9585 - val_loss: 0.1378\n",
      "\u001b[1m  67/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9577 - loss: 0.1637Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9581 - loss: 0.1437 - val_accuracy: 0.9706 - val_loss: 0.0994\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.1518 - val_accuracy: 0.9675 - val_loss: 0.1043\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9676 - loss: 0.1049 - val_accuracy: 0.9721 - val_loss: 0.0891\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9679 - loss: 0.1060 - val_accuracy: 0.9707 - val_loss: 0.0927\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9728 - loss: 0.0864 - val_accuracy: 0.9753 - val_loss: 0.0781\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9723 - loss: 0.0874 - val_accuracy: 0.9745 - val_loss: 0.0811\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9776 - loss: 0.0727 - val_accuracy: 0.9761 - val_loss: 0.0769\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9754 - loss: 0.0764 - val_accuracy: 0.9751 - val_loss: 0.0794\n",
      "313/313 - 0s - 1ms/step - accuracy: 0.9761 - loss: 0.0769\n",
      "\n",
      "Test accuracy (async): 0.9761000275611877\n",
      "313/313 - 0s - 1ms/step - accuracy: 0.9751 - loss: 0.0794\n",
      "\n",
      "Test accuracy (async): 0.9750999808311462\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "\n",
    "# Modify the asynchronous function to use functools.partial\n",
    "async def train_neural_network_async():\n",
    "    # Load the MNIST dataset asynchronously\n",
    "    loop = asyncio.get_event_loop()\n",
    "    (x_train, y_train), (x_test, y_test) = await loop.run_in_executor(None, keras.datasets.mnist.load_data)\n",
    "    \n",
    "    # Normalize the data\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    \n",
    "    # Create a simple neural network model\n",
    "    model = keras.Sequential([\n",
    "        layers.Flatten(input_shape=(28, 28)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model asynchronously using functools.partial to handle the function and its arguments\n",
    "    fit_partial = functools.partial(model.fit, x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "    await loop.run_in_executor(None, fit_partial)\n",
    "    \n",
    "    # Evaluate the model asynchronously using functools.partial\n",
    "    evaluate_partial = functools.partial(model.evaluate, x_test, y_test, verbose=2)\n",
    "    test_loss, test_acc = await loop.run_in_executor(None, evaluate_partial)\n",
    "    \n",
    "    print(\"\\nTest accuracy (async):\", test_acc)\n",
    "\n",
    "# Define a function to run two asynchronous DL models\n",
    "async def run_two_async_models():\n",
    "    print(\"\\nRunning two asynchronous DL models:\")\n",
    "    # Create two asyncio tasks to run the DL models concurrently\n",
    "    tasks = [train_neural_network_async(), train_neural_network_async()]\n",
    "    # Wait for both tasks to complete\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "await run_two_async_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asynchio for different tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
